<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>AI Tea Talks Singapore</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<style>
        .part {
            flex: 1 1 30%;
            margin: 20px;
            background: #fff;
            padding: 20px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
            min-width: 40%;
            max-width: 40%;
			display: flex;
            flex-direction: column;
            align-items: center;
			.part {
			flex: 1 1 45%; /* Adjust the width of each part */
			border: 1px solid #ccc; /* Optional: Adds a border for visual separation */
			box-sizing: border-box;
        }

        .part h2 {
            text-align: center;
        }

        .talk {
            text-align: center;
            margin-bottom: 20px;
        }

        .talk img {
            border-radius: 10%;
            height: 150px;
            margin-bottom: 10px;
        }


        .talk h3 {
            margin: 10px 0;
        }

        .talk p {
            margin: 5px 0;
        }

        .collapsible {
            background-color: #f4f4f4;
            color: #333;
            cursor: pointer;
            padding: 1px;
            width: 100%;
            border: none;
            text-align: center;
            outline: none;
            font-size: 16px;
            margin-top: 1px;
			min-width: 24%;
            max-width: 24%;
        }

		.contentwithbutton {
            padding: 0 18px;
            font-size: 16px;
            display: none;
            overflow: hidden;
            background-color: #f9f9f9;
        }


        @media (max-width: 768px) {
            .part {
                flex: 1 1 100%;
                min-width: 100%;
            }
        }
    </style>
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<span class="logo"><img src="images/logo.svg" alt="" height="100" width="100" /></span>
			<h1>AI Tea Talks Singapore</h1>
			<!-- <p>CogAI4Sci Lab @ NUS<br /> -->
				<!-- built by <a href="https://twitter.com/ajlkn">@ajlkn</a> for <a href="https://html5up.net">HTML5 UP</a>.</p> -->
		</header>

		<!-- Nav -->
		<nav id="nav">
			<ul>
				<li><a href="#intro" class="active">Introduction</a></li>
				<li><a href="#Details">Details</a></li>
				<li><a href="#Schedule">Schedule</a></li>
				<li><a href="#Invited Speakers">Invited Spearkers</a></li>
				<li><a href="#Advisory Committee">Advisory Committee</a></li> 
				<li><a href="#Organizers">Organizers</a></li>
			</ul>
		</nav>

		<!-- Main -->
		<div id="main">

			<!-- Introduction -->
			<section id="intro" class="main">
				<div class="spotlight">
					<div class="content">
						<header class="major">
							<h2>About </h2>
						</header>
						<p>
							The "AI Tea Talk Singapore" series offers a fully open platform designed to welcome experts from various sub-fields of artificial intelligence. It aims to facilitate the sharing of cutting-edge research with anyone interested in AI, both within Singapore and internationally.  </p>
						<div style="text-align: center; margin: 30px;">
							
							<p>The "AI Tea Talk Singapore" series is a community based platform led by a group of junior AI researchers in Singapore and supported by senior scientists in the field </p>
						</div>
						
						
						<!-- <ul class="actions">
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul> -->
					</div>
					<span class="image"><img src="images/pic01.jpg" alt="" height="100" width="100" /></span>
				</div>
			</section>


			<section id="Details" class="main special">
				<header class="major">
					<h2>Focus Topics</h2>
					<!-- <p class="track-description"><i>We outline the 4 tracks below:</i></p> -->
				</header>
				<!-- <ul class="statistics">
					<li class="style1">
						<span class="icon solid fa-code-branch"></span>
						<strong>5,120</strong> Etiam
					</li>
					<li class="style2">
						<span class="icon fa-folder-open"></span>
						<strong>8,192</strong> Magna
					</li>
					<li class="style3">
						<span class="icon solid fa-signal"></span>
						<strong>2,048</strong> Tempus
					</li>
					<li class="style4">
						<span class="icon solid fa-laptop"></span>
						<strong>4,096</strong> Aliquam
					</li>
					<li class="style5">
						<span class="icon fa-gem"></span>
						<strong>1,024</strong> Nullam
					</li>
				</ul> -->
				<!-- <p class="content">Nam elementum nisl et mi a commodo porttitor. Morbi sit amet nisl eu arcu faucibus
					hendrerit vel a risus. Nam a orci mi, elementum ac arcu sit amet, fermentum pellentesque et purus.
					Integer maximus varius lorem, sed convallis diam accumsan sed. Etiam porttitor placerat sapien, sed
					eleifend a enim pulvinar faucibus semper quis ut arcu. Ut non nisl a mollis est efficitur
					vestibulum. Integer eget purus nec nulla mattis et accumsan ut magna libero. Morbi auctor iaculis
					porttitor. Sed ut magna ac risus et hendrerit scelerisque. Praesent eleifend lacus in lectus aliquam
					porta. Cras eu ornare dui curabitur lacinia.</p> -->
				<!-- Inserted Text Content as an Ordered List -->
				<ul style="text-align: center;">
					<li><i> Wide range of AI fields including method development and applications</li>
				</ul>
			</section>

			<section id="Schedule" class="main special">
				<header class="major">
					<h2>Upcoming Talks</h2>
				</header>
				<div class="container">
					<div class="part">
						<p>Sep 24th 10:30 am SGT, Sep 23rd 10:30pm New York time</p>
						<div class="talk">
								<img src="images/speakers/lichaosun.png"
									alt="Lichao Sun " /></a></span>
							</a>
							<p><strong></strong>Lichao Sun </strong> </p>
							<p style="margin-top: -15px;">Lehigh University and the Mayo Clinic</p>
							<!-- <p style="margin-top: -15px;">Incoming assistant professor at Harvard University</p> -->
							<h3><strong>BiomedGPT: A generalist visionâ€“language foundation model for diverse biomedical tasks</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-2')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-2')">Abstract</button>
							<button class="collapsible" onclick="showContent('meeting-info-content-2')">Meeting Info</button>
							<div class="contentwithbutton" id="bio-content-2">
								<p> TBD</p>
							</div>
							<div class="contentwithbutton" id="abstract-content-2">
								<p>Traditional biomedical artificial intelligence (AI) models, designed for specific tasks or modalities, often exhibit limited flexibility in real-world deployment and struggle to utilize holistic information. Generalist AI holds the potential to address these limitations due to its versatility in interpreting different data types and generating tailored outputs for diverse needs. However, existing biomedical generalist AI solutions are typically heavyweight and closed source to researchers, practitioners and patients. In this talk, We will discuss the development and performance of BiomedGPT, a novel open-source, lightweight vision-language foundation model designed as a generalist AI for biomedical applications. Unlike previous solutions, BiomedGPT is both computationally efficient and accessible, achieving state-of-the-art results in 16 out of 25 benchmarks across a variety of tasks. We will present human evaluation results that underscore its effectiveness in radiology visual question answering, report generation, and summarization, with performance metrics nearing human expert levels. This talk will explore how BiomedGPT exemplifies the potential of a multi-modal, generalist approach to revolutionize medical diagnostics and improve workflow efficiency.</p>
							</div>
							<div class="contentwithbutton" id="meeting-info-content-2">
								<p>Zoom Registration: <a>https://nus-sg.zoom.us/j/86532780782</a> 
                        	<p>Zoom ID: 865 3278 0782</p> 
								<p>Open to ALL interested in AI</p> 
							</div>
								</div>
							</div>
				</div>      
 				<header class="major">
					<h2>Previous Talks</h2>
				</header>

				<div class="container">
					<div class="part">
						<p>August 22th 2024, 8PM SGT, 8AM New York Time</p>
						<div class="talk">
							<img src="images/speakers/ruyuanzhang.png"
							alt="Ru-Yuan Zhang " /></a></span>
							</a>
							<p><strong></strong>Ru-Yuan Zhang </strong> </p>
							<p style="margin-top: -15px;">Associate Professor @ Shanghai Jiao Tong University</p>
							<!-- <p style="margin-top: -15px;">Incoming assistant professor at Harvard University</p> -->
							<h3><strong>A Neural Network Approach for Human Visual Learning</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-2')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-2')">Abstract</button>
							<button class="collapsible" onclick="showContent('record-info-content-2')">Record Info</button>
							<div class="contentwithbutton" id="bio-content-2">
								<p>Dr. Zhang is currently leading the Cognitive Computational Neuroscience and Brain Imaging Group at the School of Psychology and Shanghai Mental Health Center at Shanghai Jiao Tong. Dr. Zhang has long been working at the intersection of brain science and brain-like intelligence. His research primarily focuses on the neural computational mechanisms of the human brain and artificial intelligence by combining psychophysics, Bayesian probabilistic modeling, deep learning modeling, neuromodulation, and functional magnetic resonance imaging. He has published several cognitive neuroscience papers in PNAS, eLife, J Neurosci, Neuroimage, PLoS Comput Biol, etc. Dr. Zhang's research on brain-like computation has also been published in the world's top machine learning conferences (ICML and IJCAI). He is also a reviewer for several brain science journals such as eLife, Cerebral Cortex, and machine learning conferences such as ICML, NeurIPS, IJCAI, ICLR, CVPR, etc. He is also the Area Chair of NeurIPS 2024.
</p>
							</div>
							<div class="contentwithbutton" id="abstract-content-2">
								<p>The past decade has seen a surge in the use of sophisticated AI models to reverse-engineer the human mind and behavior. This NeuroAI approach has dramatically promoted interdisciplinary research between neuroscience and AI. This talk focuses on using the neuroAI approach to elucidate human learning mechanisms. The talk will consist of two parts. First, I will present our work on the relationships between the primate visual system and artificial visual systems (i.e., deep neural networks) during the learning of simple visual discrimination tasks. Our deep learning models of biological visual learning successfully reproduce a wide range of neural phenomena observed in the primate visual system during perceptual learning. The novel predictions generated by our models are further validated against multivariate neuroimaging data in humans and multi-electrode recording data in macaques. In the second part, I will discuss our recent work on neural and computational mechanisms of how the human brain mitigates catastrophic forgetting during continual multitask learning. Leveraging neural network modeling on human learning behavior, we show that the human brain directly distills learned knowledge via elastic weight consolidation rather than other methods such as memory replay. These studies have profound implications for interdisciplinary research at the intersection of neuroscience and artificial intelligence.
</p>
							</div>
							<div class="contentwithbutton" id="record-info-content-2">
								<p>Youtube: <a href="https://youtu.be/qJyy21-LPQY">https://youtu.be/qJyy21-LPQY</a></p>
							</div>
								</div>
					 </div>
				</div> 
				
                <div class="container">
					<div class="part">
						<p>August 14th 2024, 10AM SGT/August 8th, 10PM New York Time</p>
						<p>August 22th 2024, 8PM SGT, 8AM New York Time</p>
						<div class="talk">
								<img src="https://www.microsoft.com/en-us/research/uploads/prod/2021/09/IMG_1823.jpg"
									alt="Alex Lamb ">
							</a>
							<p><strong></strong>Alex Lamb </strong> </p>
							<!-- <p style="margin-top: -15px;">Incoming assistant professor at Harvard University</p> -->
							<h3><strong>Discovering Agent-Centric Latent States in Theory and in Practice</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-2')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-2')">Abstract</button>
							<button class="collapsible" onclick="showContent('meeting-info-content-2')">Record Info</button>
							<div class="contentwithbutton" id="bio-content-2">
						        <p>Alex Lamb is a senior researcher in the AI Frontiers group at Microsoft. He completed his PhD under Yoshua Bengio and has worked on deep learning, generative models, reinforcement learning, and sequence models. He also worked on deep learning for classical Japanese document recognition as well as demand forecasting systems at Amazon.</p>
				            </div>
					       <div class="contentwithbutton" id="abstract-content-2">
						       <p>Generative AI has led to stunning successes in recent years but is fundamentally limited by the amount of data available. This is especially limiting in the embodied setting â€“ where an agent must solve new tasks in new environments. In this talk, I'll introduce the idea of compositional generative modeling, which enables generalization beyond the training data by building complex generative models from smaller constituents. I'll first introduce the idea of energy-based models and illustrate how they enable compositional generative modeling. I'll then illustrate how such compositional models enable us to synthesize complex plans for unseen tasks at inference time. Finally, I'll show how such compositionality can be applied to multiple foundation models trained on various forms of Internet data, enabling us to construct decision-making systems that can hierarchically zero-shot manner.</p>
					       </div>
					       <!-- <div class="contentwithbutton" id="meeting-info-content-2">
						   <p>Zoom link: <a href="https://nus-sg.zoom.us/j/81069690971">https://nus-sg.zoom.us/j/81069690971</a></p>
						   <p>Open to ALL</p> https://youtu.be/qJyy21-LPQY
					       </div> -->
					       <div class="contentwithbutton" id="record-info-content-2">
						       <p>Youtube: <a href="https://youtu.be/qJyy21-LPQY">https://youtu.be/qJyy21-LPQY</a></p>
					       </div>
						       </div>
					</div>
		        </div>  

				<div class="container">
					<div class="part">
						<p>July 4th 2024: 10AM SGT</p>
						<div class="talk">
								<img src="images/yilun3.png"
									alt="Yilun Du">
							</a>
							<p><strong></strong>Yilun Du</strong> </p>
							<p style="margin-top: -15px;">PhD in EECS @ MIT</p>
							<p style="margin-top: -15px;">Incoming assistant professor at Harvard University</p>
							<h3><strong>Generalizing Outside the Training Distribution through Compositional Generation</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-2')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-2')">Abstract</button>
							<button class="collapsible" onclick="showContent('record-info-content-2')">Record Info</button>
							<div class="contentwithbutton" id="bio-content-2">
								<p>Yilun Du is an incoming Assistant Professor at Harvard, starting in Fall 2025 at the Kempner Institute and Computer Science department. He is a final year PhD student in EECS at MIT, advised by Prof. Leslie Kaelbling, Prof. Tomas Lozano-Perez, and Prof. Joshua B. Tenenbaum. Yilun's research focuses on generative models, decision making, robot learning, and embodied agents. His work addresses the challenges of limited decision-making data and generalization to unseen situations using energy landscapes for composable generative models. Yilun aims to develop a decentralized generative architecture for decision-making and enhance models with reinforcement learning, with applications in fields like computational biology.</p>
							</div>
							<div class="contentwithbutton" id="abstract-content-2">
								<p>Generative AI has led to stunning successes in recent years but is fundamentally limited by the amount of data available. This is especially limiting in the embodied setting â€“ where an agent must solve new tasks in new environments. In this talk, I'll introduce the idea of compositional generative modeling, which enables generalization beyond the training data by building complex generative models from smaller constituents. I'll first introduce the idea of energy-based models and illustrate how they enable compositional generative modeling. I'll then illustrate how such compositional models enable us to synthesize complex plans for unseen tasks at inference time. Finally, I'll show how such compositionality can be applied to multiple foundation models trained on various forms of Internet data, enabling us to construct decision-making systems that can hierarchically zero-shot manner.</p>
							</div>
							<!-- <div class="contentwithbutton" id="meeting-info-content-2">
								<p>Zoom link: <a href="https://nus-sg.zoom.us/j/81069690971">https://nus-sg.zoom.us/j/81069690971</a></p>
                        		<p>Open to ALL</p> https://youtu.be/qJyy21-LPQY
							</div> -->
							<div class="contentwithbutton" id="record-info-content-2">
								<p>Youtube: <a href="https://youtu.be/qJyy21-LPQY">https://youtu.be/qJyy21-LPQY</a></p>
							</div>
								</div>
							</div>
				</div>      
				
				<div class="container">
					<div class="part">
						<p>June 26th 2024: 10AM SGT</p>
						<div class="talk">
								<img src="images/BaifengShi.jpg"
									alt="Baifeng Shi">
							</a>
							<p><strong></strong>Baifeng Shi</strong> </p>
							<p style="margin-top: -15px;">University of California, Berkeley</p>
							<h3><strong>Scaling Up Visual Pre-Training: What's Next?</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-2')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-2')">Abstract</button>
							<button class="collapsible" onclick="showContent('record-info-content-2')">Record Info</button>
							<div class="contentwithbutton" id="bio-content-2">
								<p>Baifeng Shi is a Ph.D. student advised by Prof. Trevor Darrell at UC Berkeley. He previously graduated from Peking University with a B.S. degree in computer science. Baifeng's research focuses on building generalist vision and robotic models.</p>
							</div>
							<div class="contentwithbutton" id="abstract-content-2">
								<p>Larger models, more data, and longer training are the three-pronged approaches to scaling up visual pre-training. In this talk, I will first share our recent work that challenges the necessity of larger models. We find that pre-trained and frozen smaller models run on larger image scales (e.g., 224->448->672) are generally better than larger models (e.g., Base->Large->Giant). This trend holds across a variety of vision tasksâ€”including image classification, semantic segmentation, and depth estimationâ€”as well as Multimodal LLM benchmarks and robotic tasks. We demonstrate that smaller models, when pre-trained on multiple image scales, have similar model capacities as larger models and can perform on par or even better. Next, I will share some thoughts on the future of scaling visual pre-training, specifically, whether we should shift our focus from larger models to larger images, and how to utilize bottom-up and top-down attention to scale to extremely large images without hitting the computational constraints.</p>
							</div>
							<!-- <div class="contentwithbutton" id="meeting-info-content-2">
								<p>Zoom link: <a href="https://nus-sg.zoom.us/j/86707998713">https://nus-sg.zoom.us/j/86707998713</a></p>
                        		<p>Open to ALL</p>https://youtu.be/oULYfb0sc30
							</div> -->
							<div class="contentwithbutton" id="record-info-content-2">
								<p>Youtube: <a href="https://youtu.be/oULYfb0sc30">https://youtu.be/oULYfb0sc30</a></p>
							</div>
						</div>
								
							</div>
					<div class="part">
						<p>April 17th 2024: 12PM SGT (9PM PT)</p>
						<div class="talk">
								<img src="https://natashajaques.ai/author/natasha-jaques/avatar_hu04b955ed351a495cc2c1096ede1d3b28_762133_270x270_fill_q75_lanczos_center.jpg"
									alt="Prof. Natasha Jaques">
								<!-- <img src="images/thumb/s1thumb.jpg"
								alt="Prof. Natasha Jaques"> -->
							<p><strong></strong>Prof. Natasha Jaques</strong> </p>
							<p style="margin-top: -15px;">University of Washington and Google DeepMind</p>
							<h3><strong>Reinforcement Learning with Human Feedback</strong></h3>
							<button class="collapsible" onclick="showContent('bio-content-1')">Speaker Bio</button>
							<button class="collapsible" onclick="showContent('abstract-content-1')">Abstract</button>
							<!-- <button class="collapsible" onclick="showContent('meeting-info-content-1')">Meeting Info</button> -->
							<button class="collapsible" onclick="showContent('record-info-content-1')">Record Info</button>
							<div class="contentwithbutton" id="bio-content-1">
								<p>Natasha Jaques is an Assistant Professor of Computer Science and Engineering at the University of Washington, and a Senior Research Scientist at Google DeepMind. Her research focuses on Social Reinforcement Learning in multi-agent and human-AI interactions. During her PhD at MIT, she developed techniques for learning from human feedback signals to train language models which were later built on by OpenAIâ€™s series of work on Reinforcement Learning from Human Feedback (RLHF). In the multi-agent space, she has developed techniques for improving coordination through the optimization of social influence, and adversarial environment generation for improving the robustness of RL agents. Her work has received various awards, including Best Demo at NeurIPS, an honourable mention for Best Paper at ICML, and the Outstanding PhD Dissertation Award from the Association for the Advancement of Affective Computing. Her work has been featured in Science Magazine, MIT Technology Review, Quartz, IEEE Spectrum, Boston Magazine, and on CBC radio. Natasha earned her Masters degree from the University of British Columbia, and undergraduate degrees in Computer Science and Psychology from the University of Regina.</p>
							</div>
							<div class="contentwithbutton" id="abstract-content-1">
								<p>Fine-tuning language models with reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models to human values. This talk will give a tutorial on RLHF, diving into the details of how to actually perform RL-finetuning of language models. I will cover the history of innovations leading to the form of RLHF used in ChatGPT, including my own work on KL-regularized RL fine-tuning of language models and human-centric dialog training, as well as OpenAIâ€™s early work on learning from human preferences with deep RL. Putting it all together, we will see how what has become known as RLHF integrates these techniques. We will then briefly cover recent developments and directions for future work.</p>
							</div>
							<!-- <div class="contentwithbutton" id="meeting-info-content-1">
								<p>Zoom link: <a href="https://nus-sg.zoom.us/j/123456789">https://nus-sg.zoom.us/j/123456789</a></p>
								<p>Zoom meeting ID: 846 0806 6438</p>
                        		<p>Open to ALL</p>
							</div> -->
							<div class="contentwithbutton" id="record-info-content-1">
								<p>Youtube: <a href="https://www.youtube.com/watch?v=VOgrYxFe-r0">https://www.youtube.com/watch?v=VOgrYxFe-r0</a></p>
							</div>
								</div>
							</div>
				</div>
			</section>
			<script>
				function showContent(contentId) {
				var contents = document.querySelectorAll('.contentwithbutton');
				var buttons = document.querySelectorAll('.collapsible');
				contents.forEach(content => {
					if (content.id === contentId) {
						content.style.display = content.style.display === 'block' ? 'none' : 'block';
					} else {
						content.style.display = 'none';
					}
				});
				buttons.forEach(button => {
					if (button.getAttribute('onclick').includes(contentId)) {
						button.classList.toggle('active');
					} else {
						button.classList.remove('active');
					}
				});
			}

			</script>
		
			<script>
				document.addEventListener('DOMContentLoaded', function() {
					// Get elements
					var speakerImageElement = document.querySelector('.speaker-image');
					var speakerNameElement = document.querySelector('.speaker-info strong');
					var institutionElement = document.querySelector('.speaker-info div:nth-child(2)');
					var titleElement = document.querySelector('.presentation-title strong');
					var descriptionElement = document.querySelector('.presentation-description');
			
					// Presentation items
					var presentationItems = [
						{ speakerName: 'Speaker Nameaaa', institution: 'Institution 1', title: 'Presentation Title', description: 'Presentation Description 1' },
						{ speakerName: 'Speaker Nameaaa', institution: 'Institution 2', title: 'Presentation Title', description: 'Presentation Description 1' },
						{ speakerName: 'Speaker Name', institution: 'Institution 3', title: 'Presentation Title', description: 'Presentation Description 2' },
						{ speakerName: 'Speaker Name', institution: 'Institution 4', title: 'Presentation Title', description: 'Presentation Description 2' }
						// Add more presentation items as needed
					];
			
					// Update details when a presentation item is clicked
					function showPresentationDetails(index) {
						var presentation = presentationItems[index];
						speakerImageElement.src = 'speaker-image.jpg'; // Update with the actual speaker image
						speakerNameElement.innerText = presentation.speakerName;
						institutionElement.innerText = presentation.institution;
						titleElement.innerText = presentation.title;
						descriptionElement.innerText = presentation.description;
					}
			
					// Attach click event listeners to each presentation item
					var presentationListItems = document.querySelectorAll('.presentation-item');
					presentationListItems.forEach(function(item, index) {
						item.addEventListener('click', function() {
							showPresentationDetails(index);
						});
					});
				});
			
				function viewSlides() {
					// Add logic to handle viewing slides
					alert('Viewing slides...');
				}
			
				function viewRecord() {
					// Add logic to handle viewing record
					alert('Viewing record...');
				}

				function toggleYear(yearId) {
					var yearContent = document.querySelector('#' + yearId + ' .year-content');
					yearContent.style.display = (yearContent.style.display === 'block') ? 'none' : 'block';
				}
			</script>


			<section id="Previous talks" class="main special">
				<header class="major">
					<h2>Invited Spearkers</h2>
				</header>
				<ul class="features">
					<h2>Coming Soon</h2>
					<!-- <li>
						<span class="image"><a href="https://scholar.google.com/citations?user=W-4N_2gAAAAJ&hl=en"><img
									src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=W-4N_2gAAAAJ&citpid=6"
									alt="" height="200" width="200" /></a></span>
						<h3>Konstantinos N. Platanioits</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p>
					</li> -->

				</ul>
				<!-- <footer class="major">
					<ul class="actions special">
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer> -->
			</section>
			


			<!-- First Section -->
			<section id="Organizers" class="main special">
				<header class="major">
					<h2>Organizers</h2>
				</header>
				<ul class="features">
					<li>
						<span class="image"><a href="https://kaiwang960112.github.io/"><img
									src="https://kaiwang960112.github.io/src/crop_kw.jpg" alt="" height="200"
									width="200" /></a></span>
						<h3>Kai Wang</h3>
						<h3 style="margin-top: -15px;">Ph.D. Student</h3>
						<h3 style="margin-top: -15px;">Data Science/Computing @ NUS</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->

						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>

					<li>
						<span class="image"><a href="https://baileytrang.github.io//"><img
									src="https://baileytrang.github.io/assets/bio3.png" alt="" height="200"
									width="200" /></a></span>
						<h3>Trang Nguyen</h3>
						<h3 style="margin-top: -15px;">Research Assistant - Medicine @ NUS</h3>
						<h3 style="margin-top: -15px;">PhD Student - CS @ Stanford</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>

					<li>
						<span class="image"><a href="https://www.linkedin.com/in/srinivas-anumasa-phd-70b45324/"><img
									src="images/SrinivasAnumasa.jpeg" alt="" height="200"
									width="200" /></a></span>
						<h3>Srinivas Anumasa</h3>
						<h3 style="margin-top: -15px;">Research fellow</h3>
						<h3 style="margin-top: -15px;"> NUS</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>

					
					<li>
						<span class="image"><a href="https://scholar.google.com/citations?user=btxQyh8AAAAJ&hl=en"><img
									src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=btxQyh8AAAAJ&citpid=8" alt="" height="200"
									width="200" /></a></span>
						<h3>Lalithkumar Seenivasan</h3>
						<h3 style="margin-top: -15px;">PhD/Research fellow</h3>
						<h3 style="margin-top: -15px;"> NUS/Johns Hopkins</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>

					<li>
						<span class="image"><a href="https://ranxuming.github.io"><img
									src="images/xuming.png" alt="" height="200"
									width="200" /></a></span>
						<h3>Xuming Ran</h3>
						<h3 style="margin-top: -15px;">Research Assistant</h3>
						<h3 style="margin-top: -15px;">Medicine @ NUS</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					
					<li>
						<span class="image"><a href="http://jayneelvora.com/"><img
									src="images/committee/JayneelVora.jpg" alt="" height="200"
									width="200" /></a></span>
						<h3>Jayneel Vora</h3>
						<h3 style="margin-top: -15px;">PhD Student</h3>
						<h3 style="margin-top: -15px;">CS @ UC Davis</h3>
						<!-- <h4 style="margin-top: 5px; margin-bottom: 15px;">Supporter</h4> -->
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
				</ul>
				<!-- <footer class="major">
					<ul class="actions special">
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer> -->
			</section>

			<!-- Second Section -->
			
			<!-- You can put me as "Dianbo Liu, advisor,  NUS,point of contact at Medicine/Engineering" ,"Yueming JIn,advisor, NUS , point of contact at Engineering", "Yang You,advisor, NUS , point of contact at Computing", "VIncent Tan,advisor, NUS , point of contact at Math/Engineering", "Jonathan Scarlet, advisor,NUS , point of contact at CS/data science/math" -->

		
			<section id="Advisory Committee" class="main special">
				<header class="major">
					<h2>Advisory Committee</h2>
				</header>
				<ul class="features">
					<li>
						<span class="image"><a href="https://www.cogai4sci.com/"><img
									src="images/DianboLiu.jpeg" alt="" height="200"
									width="200" /></a></span>
						<h3>Dianbo Liu</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">Medicine/Engineering @ NUS</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					<li>
						<span class="image"><a href="https://yuemingjin.github.io/"><img
									src="images/yuemingjin.jpeg"
									alt="" height="200" width="200" /></a></span>
						<h3>Yueming Jin</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">Engineering @ NUS</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					<li>
						<span class="image"><a href="https://www.comp.nus.edu.sg/~youy/"><img
									src="data:image/jpeg;base64,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"
									alt="" height="200" width="200" /></a></span>
						<h3>Yang You</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">Computing @ NUS</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					<li>
						<span class="image"><a href="https://cde.nus.edu.sg/ece/staff/tan-yan-fu-vincent/"><img
									src="images/VincentTan.jpeg"
									alt="" height="200" width="200" /></a></span>
						<h3>Vincent Y. F. Tan</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">Math/Engineering @ NUS</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					<li>
						<span class="image"><a href="https://www.comp.nus.edu.sg/~scarlett/"><img
									src="https://www.comp.nus.edu.sg/~scarlett/images/photo.jpg" alt=""
									height="200" width="200" /></a></span>
						<h3>Jonathan Scarlett</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">CS/Data Science/Math @ NUS</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					<li>
						<span class="image"><a href="https://yong-wang.org"><img
									src="images/committee/yongwang.png" alt=""
									height="200" width="200" /></a></span>
						<h3>Yong Wang</h3>
						<h3 style="margin-top: -15px;">Advisor</h3>
						<h3 style="margin-top: -15px;">CCDS @ NTU</h3>
						<!-- <p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p> -->
					</li>
					
				</ul>
				<!-- <footer class="major">
					<ul class="actions special">
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer> -->
			</section>

			<!-- Get Started -->
			<!-- <section id="cta" class="main special">
				<footer class="major">
					<ul class="actions special">
						<li><a href="generic.html" class="button primary">Get Started</a></li>
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer>
			</section> -->

		</div>

		<!-- Footer -->
		<footer id="footer">
			<section>
				<!-- <h2>Cognitive AI for Science Lab</h2>
				<h2>@ National University of Singapore</h2> -->
				<dl class="alt">
					<dt>Email</dt>
					<dd><a href="#">teatalkai@gmail.com</a></dd>
				</dl>
				<ul class="icons">
					<li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>
					<li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
					<li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>
					<li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
					<li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>
				</ul>
			</section>
			<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>
